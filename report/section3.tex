\section{Semantic Analysis}

\subsection{Phases \& Design}

As described in \ref{eyecandy} the Semantic Analysis phase
should be split into a number of sub-phases specifically: symbol
resolution, de-sugaring/type inference and type checking.

However, these steps can be combined together into a single
phase. There are benefits and downsides to both approaches. The
main benefit of using the first approach is a reduction in
algorithmic complexity. The logic can be separated into
different phases with ease and information from one phase can be
propagated to another. The downside of this approach is that it
actually adds more code for maintenance, since each individual
sub-phase will probably need to be implemented as its own
visitor. The other down side is error management. If an error
occurs in a particular phase due to separation, a mechanism for
propagation needs to be devised which again further increases
complexity. Of course by the very nature of this argument the
monolithic approach does not suffer for the issues that the
sub-phases approach has. However, it significantly increases
complexity since all sub-phases are being done in a single
phase. The other more glaring issue is the fact that it is much
more difficult to resolve symbols before-hand, in a nice way.

\begin{lstlisting}[caption={The \texttt{visit(Program *)} method
in the \texttt{AnalysisVisitor} class, showing the hack used for
resolving function symbols before-hand
(analysis/AnalysisVisitor.cpp).},label=lst:funcdeclhack]
void AnalysisVisitor::visit(core::Program *prog) {
    // HACK: this is piece of code to support
    // mutually exclusive recursion such as in test45.parl
    for (auto &stmt : prog->stmts) {
        if (isFunction.check(stmt.get())) {
            try {
                registerFunction(
                    dynamic_cast<core::FunctionDecl *>(
                        stmt.get()
                    )
                );
            } catch (SyncAnalysis &) {
                // noop
            }
        }
    }

    for (auto &stmt : prog->stmts) {
        try {
            stmt->accept(this);
        } catch (SyncAnalysis &) {
            // noop
        }
    }
}
\end{lstlisting}

You would want to do so to allow for the location agnostic
function declarations.

Now, since the current compiler's semantic analysis is done in a
single phase, it suffers from some of the issues described
above, specifically an unneat solution to the function
declaration problem (see \listref{funcdeclhack}).

\subsection{The \texttt{Environment} Tree}

Some terminology is required to properly describe the number of
structures which will be used in this section. The following
terms are critical and need to be differentiated properly:

\begin{itemize}
    \item \texttt{SymbolTable};
    \item \texttt{SymbolTableStack};
    \item \texttt{Environment};
    \item \texttt{EnvStack};
    \item and, \texttt{RefStack}.
\end{itemize}

During semantic analysis there is a need for specific data
structures which facilitate scoping rules, type checking, etc.

The most basic data structure which achieves this, is a single
\texttt{SymbolTable}. A symbol table in its simplest form, is a
wrapper around a hash map whose keys are identifiers and values
are \texttt{Symbol}s (or any structure which is capable of
storing variable and function signatures).

This approach is quite limiting since it restricts user of the
language to a single global scope. Therefore, this structure is
not a sufficient solution for most toy-languages let alone
production-ready languages.

A better solution is using a stack of symbol tables. This allows
symbol tables to shadow each other allowing for the reuse of
identifiers. Additionally, this opens up the possibility of
implementing modules at the language-level. The likelihood that
names will be reused across different modules is quite high and
being able to scope modules so they do not interfere with global
scope and each other is necessary for any sufficiently large
project.

\begin{figure}[H]
\centering
\begin{mdframed}[backgroundcolor=OffWhite]
\includegraphics[width=\linewidth]{scopedcode.pdf}
\end{mdframed}
\caption{A \texttt{PArL} function with annotated scopes.}
\label{fig:scopeannotatedcode}
\end{figure}

The basic premise of using a symbol table stack is described in
the algorithm below and \figref{graphicaldecpiction}.
A new symbol table, also referred to as a scope, is pushed onto
a stack only for specific types of AST nodes. The node is then
processed, were ``processing'' often times means considering all
the sub-children of the node, and then that is, processing
finishes, the scope is popped. In the context of a purely stack
based implementation this implies that, scopes are temporary
that is, they are lost after being popped.

\begin{algorithm}[H]
\KwData{$N$ the AST node, $S$ the symbol table stack}

\Begin{
    \If{$N$ opens a scope}{
        PushScope($S$)\;
    }
    ProcessNode($N$)\;
    \If{$N$ opens a scope}{
        PopScope($S$)\;
    }
}
\caption*{Basic depiction of \texttt{SymbolTableStack} usage.}
\end{algorithm}

\begin{figure}[H]
\centering
\begin{mdframed}[backgroundcolor=OffWhite]
\includegraphics[width=\linewidth]{symboltablestack.pdf}
\end{mdframed}
\caption{Behaviour of the \texttt{SymbolTableStack} when
considering the code in \figref{scopeannotatedcode}.}
\label{fig:graphicaldecpiction}
\end{figure}

\label{sss:memoryadvantage}The main advantage of using this
approach is that the worst case memory usage is $O(DI)$, where
$D$ is the length of a longest chain of open scopes and $I$ is
the size of largest number of variable declarations within a
scope.

However, due to the temporary nature of this approach it does
not lend itself well to a multi-phase approach. This is because
at each phase \texttt{SymbolTable}s have to be regenerated
increasing the complexity of each individual phase.

Instead a different approach was used. This approach uses an
\href{https://craftinginterpreters.com/statements-and-state.html#nesting-and-shadowing}{Environment
Tree} (which has also been inspired by
\href{https://craftinginterpreters.com/}{Crafting
Interpreters}).

The notion of an \texttt{Environment} is essentially, the same
as a \texttt{SymbolTable}. The only significant change is the
addition of vector of unique pointers to other \\
\texttt{Environment}s (see \listref{envclass}).

\begin{lstlisting}[escapechar=!,caption={The
\texttt{Environment} class with \texttt{mChildren} highlighted
(backend/Environment.hpp).}, label=lst:envclass]
class Environment {
   public:
    enum class Type {
        GLOBAL,
        IF,
        ELSE,
        FOR,
        WHILE,
        FUNCTION,
        BLOCK
    };

    void addSymbol(
        std::string const& identifier,
        Symbol const& Symbol
    );
    [[nodiscard]] std::optional<Symbol> findSymbol(
        std::string const& identifier
    ) const;
    Symbol& getSymbolAsRef(std::string const& identifier);

    [[nodiscard]] Environment* getEnclosing() const;
    void setEnclosing(Environment* enclosing);

    [[nodiscard]] Type getType() const;
    void setType(Type type);

    [[nodiscard]] std::optional<std::string> getName(
    ) const;
    void setName(const std::string& name);

    std::vector<std::unique_ptr<Environment>>& children();

    [[nodiscard]] bool isGlobal() const;

    [[nodiscard]] size_t getIdx() const;
    void incIdx();
    void incIdx(size_t inc);

    [[nodiscard]] size_t getSize() const;
    void setSize(size_t size);

   private:
    std::unordered_map<std::string, Symbol> mMap{};
    Type mType{Type::GLOBAL};
    std::optional<std::string> mName{};
    Environment* mEnclosing{nullptr};
    !\colorbox{UMPaleRed}{std::vector<std::unique_ptr<Environment>> mChildren\{\};}!
    size_t mSize{0};
    size_t mIdx{0};
};
\end{lstlisting}

The additional fields present in the \texttt{Environment} class
are there to cater for the needs of each of the stages.

Specifically,\label{sss:extrafields} \texttt{mType} and
\texttt{mName} are used during semantic analysis and
\texttt{mSize} and \texttt{mIdx} are used during code
generation.

Additionally, it is preferable if the interface with which the
phases interact with the \texttt{Environment} tree is identical
to that of a \texttt{SymbolTableStack} that is, the same
\texttt{push()} and \texttt{pop()} methods are used.

Now to facilitate this another two classes need to be defined
\texttt{EnvStack} and \\ \texttt{RefStack}. The main difference
between \texttt{EnvStack} and \texttt{RefStack} is that the
purpose of \texttt{EnvStack} is to construct the
\texttt{Environment} tree whilst \texttt{RefStack} traverses the
environment tree. Due to this \texttt{EnvStack} is strictly
speaking only required for symbol resolution. However, in the
current implementation since symbol resolution is combined with
type checking, the \texttt{Environment} tree is generated at the
same time, as it is being type checked.

Additionally, in both an \texttt{EnvStack} and a
\texttt{RefStack}, the creation and traversal of the
\texttt{Environment} tree is managed via \texttt{push()} and
\texttt{pop()} methods.

In an \texttt{EnvStack} \texttt{push()} works by creating a new
\texttt{Environment}, setting the enclosing \texttt{Environment}
to the current \texttt{Environment} and changing the current \\
\texttt{Environment} to the new \texttt{Environment} (see
\listref{envstackpush}). \texttt{pop()} makes use of the
\texttt{mEnclosing} field in the current \texttt{Environment}.
It just sets the current \texttt{Environment} to the enclosing
\texttt{Environment}, essentially moving up an
\texttt{Environment} (see \listref{envstackpop}).

\lstinputlisting[linerange={12-22}, caption={The
\texttt{pushEnv()} method in the \texttt{EnvStack} class
(analysis/EnvStack.cpp).}, label=lst:envstackpush
]{analysis/EnvStack.cpp}

\lstinputlisting[linerange={24-28}, caption={The
\texttt{popEnv()} method in the \texttt{EnvStack} class
(analysis/EnvStack.cpp).}, label=lst:envstackpop
]{analysis/EnvStack.cpp}

The implementations in \texttt{RefStack} are slightly different.
This is because the compiler has to perform a step-wise
left-first depth-first traversal. The best way to do this is to
make use of a stack and the procedures in \listref{refpush} and
\listref{refpop} (see \figref{refstackdryrun}, for the initial
segments of a traversal).

\lstinputlisting[linerange={7-17}, caption={The
\texttt{pushEnv()} method in the \texttt{RefStack} class
(ir\_gen/RefStack.cpp)}, label=lst:refpush
]{ir\_gen/RefStack.cpp}

\lstinputlisting[linerange={37-43}, caption={The
\texttt{popEnv()} method in the \texttt{RefStack} class
(ir\_gen/RefStack.cpp)}, label=lst:refpop
]{ir\_gen/RefStack.cpp}

\begin{marker}
The correctness of the traversal entirely depends on the usage
of the \texttt{push()} and \texttt{pop()} methods. If used
incorrectly the traversal might be incorrect or the program
might crash. Of course, this is only an implementation detail
that is, if used correctly by the compiler developer then, no
such issue should occur.
\end{marker}

\begin{figure}[H]
\centering
\begin{mdframed}[backgroundcolor=OffWhite]
\includegraphics[width=\linewidth]{refstackdryrun.pdf}
\end{mdframed}
\caption{The initial steps of a traversal performed by
\texttt{RefStack}.}
\label{fig:refstackdryrun}
\end{figure}

In the current implementation of \texttt{PArL} three types of
nodes control scopes, these are: \texttt{Block}s,
\texttt{ForStmt}s and \texttt{FunctionDecl}s. There is also a
slight particularity in that, \texttt{ForStmt}s and
\texttt{FunctionDecl}s as per the grammar actually, cause two
scopes to open. This has an effect on the shadowing rules of the
language. In particular it presents the following question:
Should the language allow for-loop variable declarations and
function parameters to be shadowed in the body of the respective
statement?

For simplicities sake in \texttt{PArL} a second scope is being
opened and hence, immediate shadowing is allowed. However there
is no particular consensus on this issue, for example in \CC{}
shadowing of function parameters or for-loop variable
declarations is not allowed since they create a single scope,
but Rust allows shadowing for the same variable in the same
scope without any problems.

% \begin{figure}[H]
% \centering
% \begin{mdframed}[backgroundcolor=UMPaleRed]
% \includegraphics[width=\linewidth]{scopedcode2.pdf}
% \end{mdframed}
% \caption{Construction of an \texttt{Environment} tree.}
% \label{fig:scopedcode2}
% \end{figure}

\subsection{Actual Semantic Analysis}

Having the necessary data structures in place the discussion
will now revolve around Semantic Analysis that is, the process
of making sure the meaning of the program is correct.

There are four main areas of interest which shall be discussed:
the \textbf{symbol type}, \textbf{symbol registration/search},
\textbf{type checking} and \textbf{return statement
verification}.

\subsubsection{The \texttt{Symbol} Type}

Within \texttt{PArL} functions are special because they are not
treated as values. This means that the \texttt{Symbol} type is
larger than the \texttt{Primitve} type referenced in
\ref{sss:primitive}. It has to support both variables and
functions, hence the \texttt{Symbol} type is truly the union of
two different types: \texttt{VariableSymbol} and
\texttt{FunctionSymbol}.

\begin{lstlisting}[caption={ \texttt{VariableSymbol} and
\texttt{FunctionSymbol} class declarations
(backend/Symbol.hpp).},label=lst:symbols]
struct VariableSymbol {
    size_t idx{0};
    core::Primitive type;

    ...
};

struct FunctionSymbol {
    size_t labelPos{0};
    size_t arity{0};
    std::vector<core::Primitive> paramTypes;
    core::Primitive returnType;

    ...
};
\end{lstlisting}

The additional fields present (see \listref{symbols}), within
said \texttt{Symbol}s helps reduce complexity further down the
pipeline, especially in code generation.

\begin{note}
Only primitives are comparable. Being able to compare the
\texttt{Symbol}s that is, adding said logic in the
\texttt{Symbol} class violates separation of behaviour and
state.
\end{note}

\subsubsection{\texttt{Symbol} Registration \& Search}

A \texttt{Symbol} in \texttt{PArL} is an attribute associated
with an identifier (a string). One of the main jobs of semantic
analysis is to solidify these associations from the AST into
each currently \texttt{Environment}. In \texttt{PArL} the only
nodes which are meant to cause a registration are the Variable
and Function Declaration nodes.

The following two considerations are the only important
considerations for registration: an identifier is never
registered twice with in the same scope and function identifiers
are globally unique that is, they cannot be shadowed.

\lstinputlisting[ linerange={926-963}, caption={The
\texttt{visit(FormalParam *)} method in the
\texttt{AnalysisVisitor} class (analysis/AnalysisVisitor.cpp).},
label=lst:internaltypesys ]{analysis/AnalysisVisitor.cpp}

Searching happens when an identifier in a none-declaration node
is met. The procedure for searching basically requires querying
the current environment for the symbol associated with the
identifier. If nothing is found climb to the enclosing scope and
repeat the process. If the root node or \emph{terminating node}
is reached and no associated symbol is found that means that the
identifier is unbound.

\begin{note}
The specification of a \emph{terminating node} (a
\texttt{Environment*}) is important. This is because it allows
the analyser to restrict access to outer scopes when necessary.
The main example of this is function declarations. In
\texttt{PArL} functions are (for the most) part pure, that is
they do not produce side-effect at a language level. To enforce
this, functions are not allowed to access any state outside of
their own scope. The only exception to this fact is the usage of
built-ins like \texttt{__write} which directly effect the
simulator.
\end{note}

This is where one of the extra fields mentioned in
\ref{sss:extrafields}, specifically \texttt{mType} is used
because it allows scopes to be of different types and this is
necessary to find function scopes. For example in
\listref{visitvariable}, \texttt{findEnclosingEnv()} is being
used to find the closest enclosing function scope and if no such
scope is found an empty optional is returned. Then searching
terminates on the stopping scope which is either global or an
enclosing function scope.

\begin{lstlisting}[caption={The \texttt{visit(Variable *)}
method in the \texttt{AnalysisVisitor} class
(analysis/AnalysisVisitor.cpp).},label=lst:visitvariable]
void AnalysisVisitor::visit(core::Variable *expr) {
    std::optional<Environment *> stoppingEnv =
        findEnclosingEnv(Environment::Type::FUNCTION);

    std::optional<Symbol> symbol{findSymbol(
        expr->identifier,
        stoppingEnv.has_value() ? *stoppingEnv
                                : mEnvStack.getGlobal()
    )};

    if (!symbol.has_value()) {
        error(
            expr->position,
            "{} is undefined",
            expr->identifier
        );
    }

    ...
\end{lstlisting}

\subsubsection{Type Checking}

This is the most tedious aspect of semantic analysis. Each
individual case where the types affect the behaviour of program
or are simply not allowed have to be considered. For this the
\texttt{AnalysisVisitor} uses the field \texttt{mReturn} which
is essentially used as the return of a visit, see
\listref{binaryreturn}.

\begin{lstlisting}[caption={A part of the \texttt{visit(Binary
*)} method in the \texttt{AnalysisVisitor} class
(analysis/AnalysisVisitor.cpp).},label=lst:binaryreturn]
void AnalysisVisitor::visit(core::Binary *expr) {
    expr->left->accept(this);
    auto leftType{mReturn};

    expr->right->accept(this);
    auto rightType{mReturn};

    ...
\end{lstlisting}

In terms of design a strict approach was chosen, that is no
implicit casting takes place. Operations are not capable of
operating with two distinct types, for example \texttt{5 / 2.0}
is not allowed. Instead operations which should support multiple
types have been overloaded (later on in code generation). For
example, \texttt{__print 5 / 2} outputs 2, \texttt{__print 5 /
2.0} is a type error and \texttt{__print 5.0 / 2.0} outputs 2.5.

\begin{lstlisting}[caption={Another part of the
\texttt{visit(Binary *)} method in the \texttt{AnalysisVisitor}
class (analysis/AnalysisVisitor.cpp).},label=lst:typechecking2]
...

case core::Operation::ADD:
case core::Operation::SUB:
    if (leftType.is<core::Array>()) {
        error(
            expr->position,
            "operator {} is not defined on array "
            "types",
            core::operationToString(expr->op)
        );
    }

    if (leftType != rightType) {
        error(
            expr->position,
            "operator {} expects both operands to "
            "be of same type",
            core::operationToString(expr->op)
        );
    }

    mReturn = leftType;
    break;

...
\end{lstlisting}

Of course the remainder of the \texttt{AnalysisVisitor} is
essentially, type checking of the form present in
\listref{typechecking2}.

\subsubsection{Return Statement Verification}

\begin{lstlisting}[caption={Checking whether a return statement
is inside a function declaration in the \texttt{visit(ReturnStmt
*)} method in the \texttt{AnalysisVisitor} class
(analysis/AnalysisVisitor.cpp).},label=lst:returninsidefunc]
...

std::optional<Environment *> optEnv =
    findEnclosingEnv(Environment::Type::FUNCTION);

if (!optEnv.has_value()) {
    error(
        stmt->position,
        "return statement must be within a "
        "function block"
    );
}

...
\end{lstlisting}

The only non-trivial check is that of a return statement. First
of all, return statements must be enclosed within functions,
otherwise it is a semantic error (see
\listref{returninsidefunc}).

\begin{lstlisting}[caption={Checking whether the return
expression has the same type as the function return type in the
\texttt{visit(ReturnStmt *)} method in the
\texttt{AnalysisVisitor} class
(analysis/AnalysisVisitor.cpp).},label=lst:returntype]
...

Environment *env = *optEnv;

std::string enclosingFunc = env->getName().value();

auto funcSymbol = env->getEnclosing()
                      ->findSymbol(enclosingFunc)
                      ->as<FunctionSymbol>();

if (exprType != funcSymbol.returnType) {
    error(
        stmt->position,
        "incorrect return type in function {}",
        enclosingFunc
    );
}

...
\end{lstlisting}

Additionally, they must have the same return type as the
enclosing function (see \listref{returntype}), and finally and
most importantly, \textbf{a function must return in all possible
branches}. Additionally, the implementation \textbf{should be
capable of recognising unreachable areas of code}.

\begin{marker}
\label{sss:returnissue} Not stopping when an unreachable code
segment is met could result in an invalid assessment of whether
a function returns from all branches or not.
\end{marker}

During the first iteration of the compiler, the mechanism for
checking the return type was embedded directly into the
\texttt{AnaylsisVisitor}. However, their is slight problem with
this approach. If an unreachable segment of code is met to avoid
the \hyperref[sss:returnissue]{issue} mentioned above the
remainder of the unreachable code cannot be type checked. Of
course this is a problem since such behaviour, would mean that
the compiler can ignore semantically incorrect code and still
produce VM instructions.

To solve this issue a separate visitor, \texttt{ReturnVisitor},
was created to handle checking that functions returns from all
possible branches. This allows for return statement verification
to  happen after type checking, circumventing any of the above
discussed issues.

The mechanism which \texttt{ReturnVisitor} uses to establish
whether a function returns or not is using a class member
\texttt{mBranchReturns}.

This member is a boolean and it is explicitly set to true only
by a return statement. Function declarations reset the
\texttt{mBranchReturns} to false and other statements which do
not exhibit branching do not modify the value of
\texttt{mBranchReturns}. This means that the only statements
which effect \texttt{mBranchRetruns} are if-else statements,
for-loops and while-loops.

For-loops and while-loops reset \texttt{mBranchReturns} to false
after their block of statements. This is because entry into the
body of the loop (both while and for) is conditional that is, a
program might never enter into the body of the loop. Therefore,
it is not enough to return from within the body of the loop.

\begin{lstlisting}[caption={The \texttt{visit(IfStmt *)} method
in the \texttt{ReturnVisitor} class
(analysis/ReturnVisitor.cpp).},label=lst:iftypecheck]
void ReturnVisitor::visit(core::IfStmt *stmt) {
    stmt->thenBlock->accept(this);
    bool thenBranch = mBranchReturns;

    bool elseBranch = false;

    if (stmt->elseBlock) {
        stmt->elseBlock->accept(this);
        elseBranch = mBranchReturns;
    }

    mBranchReturns = thenBranch && elseBranch;
}
\end{lstlisting}

If-else statements are different because if the `then' block
returns and the `else' block returns then, the whole if-else
statement returns, otherwise the if-else statement does not
return. This is essentially a logical and between the results of
the visitor from visiting the `then' and `else' blocks (see
\listref{iftypecheck}).

\begin{lstlisting}[escapechar=!, caption={The
\texttt{visit(Block *)} method in the \texttt{ReturnVisitor}
class with the segment pruning statements highlighted
(analysis/ReturnVisitor.cpp).},label=lst:dropinblock]
void ReturnVisitor::visit(core::Block *block) {
    size_t i = 0;

    for (; i < block->stmts.size(); i++) {
        block->stmts[i]->accept(this);

        if (mBranchReturns) {
            i++;

            break;
        }
    }

    if (i < block->stmts.size()) {
        core::Position start = block->stmts[i]->position;

        warning(
            start,
            "statements starting from line {} upto line {} "
            "are unreachable",
            start.row(),
            block->position.row()
        );
    }

    !\colorbox{UMPaleRed}{
    for (; i < block->stmts.size(); i++) \{\ block->stmts.pop_back();\ \}}!
}
\end{lstlisting}

Finally, in the block statements if one of the statements inside
manages to successfully return, the remaining statements will
never be reached and hence the user can be notified and the
statements can be dropped (see \listref{dropinblock}).
